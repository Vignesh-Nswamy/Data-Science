---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.4
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import KFold
from sklearn import linear_model
import matplotlib.pyplot as plt
from sklearn import metrics
from sklearn.svm import SVC
import seaborn as sns
import pandas as pd
import numpy as np
import os
```

```{python}
data = pd.read_csv(os.getcwd() + '\data\merged_train.csv')
data.head()
```

**Splitting data using the hold-out method**

```{python}
columns = np.array([i for i in range(4, 17)], dtype=np.intp) # All columns
# columns = np.array([i for i in range(4, 17)], dtype=np.intp) # All columns
print('Columns being used for building the classifier: {}'.format( data.iloc[:, columns].columns ))
x_train, x_test, y_train, y_test = train_test_split(data.iloc[:, columns], data['Party'], train_size=0.75, random_state=0)
```

**Standardizing the test and training data**

```{python}
scaler = StandardScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)
```

**Method for printing evaluation metrics**

```{python}
def evaluate(y_test, y_pred):
    return_str = ''
    accuracy = metrics.accuracy_score(y_test, y_pred)
    return_str += 'Accuracy: {}'.format( accuracy ) + '\n'
    return_str += 'Error: {}'.format( 1 - accuracy ) + '\n'
    return_str += 'Precision: {}'.format( metrics.precision_score(y_test, y_pred, average = None) ) + '\n'
    return_str += 'Recall: {}'.format( metrics.recall_score(y_test, y_pred, average = None) ) + '\n'
    return_str += 'F1 Score: {}'.format( metrics.f1_score(y_test, y_pred, average = None) )
    return return_str
```

## Decision Tree Classifier

```{python}
def decision_tree(x_train, y_train):
    classifier = DecisionTreeClassifier(criterion = "entropy", random_state = 0)
    classifier.fit(x_train, y_train)
    y_pred = classifier.predict(x_test)
    conf_matrix = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot = True, fmt = ".3f", square = True, cmap = plt.cm.Blues)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion matrix')
    plt.tight_layout()
    print(evaluate(y_test, y_pred))
```

## K-Nearest Neighbours Classifier

```{python}
def k_nearest_neighbors(x_train, y_train):
    classifier = KNeighborsClassifier(n_neighbors = 3)  
    classifier.fit(x_train, y_train)
    y_pred = classifier.predict(x_test)
    conf_matrix = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot = True, fmt = ".3f", square = True, cmap = plt.cm.Blues)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion matrix')
    plt.tight_layout()
    print(evaluate(y_test, y_pred))
```

## Naive Bayes Classifier

```{python}
def naive_bayes(x_train, y_train):
    classifier = GaussianNB()  
    classifier.fit(x_train, y_train)
    y_pred = classifier.predict(x_test)
    conf_matrix = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot = True, fmt = ".3f", square = True, cmap = plt.cm.Blues)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion matrix')
    plt.tight_layout()
    print(evaluate(y_test, y_pred))
```

## SVM Classifier

```{python}
def svm(x_train, y_train, kernel='rbf'):
    classifier = SVC(kernel=kernel)  
    classifier.fit(x_train, y_train)
    y_pred = classifier.predict(x_test)
    conf_matrix = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot = True, fmt = ".3f", square = True, cmap = plt.cm.Blues)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion matrix')
    plt.tight_layout()
    print(evaluate(y_test, y_pred))
```

## Test Different Classifiers

```{python}
decision_tree(x_train, y_train)
```

```{python}
k_nearest_neighbors(x_train, y_train)
```

```{python}
naive_bayes(x_train, y_train)
```

```{python}
svm(x_train, y_train)
```

```{python}

```
