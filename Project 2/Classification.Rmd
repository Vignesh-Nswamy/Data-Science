---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.1'
      jupytext_version: 1.2.4
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

```{python}
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.neighbors import KNeighborsClassifier 
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import KFold
from sklearn.pipeline import Pipeline
from sklearn import linear_model
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn import metrics
import seaborn as sns
import pandas as pd
import numpy as np
import os
```

```{python}
data = pd.read_csv(os.getcwd() + '\data\merged_train.csv')
```

**Splitting data using the hold-out method**

```{python}
# columns = np.array([i for i in range(4, 16)], dtype=np.intp) # All columns
columns = np.array([3, 4, 5, 7, 9, 10, 13, 14, 15], dtype=np.intp)
# columns = np.array([3, 4, 5, 7, 10, 14, 15], dtype=np.intp)
# columns = np.array([3, 4, 5, 6, 7, 11, 14, 15], dtype=np.intp)

# print('Columns being used for building the classifier: {}'.format( data.iloc[:, columns].columns ))

x_train, x_test, y_train, y_test = train_test_split(data.iloc[:, columns], data['Party'], train_size=0.75, random_state=0)
```

**Building a classifier**

```{python}
def train_classifier(clf, x_train, y_train):
    classifier = Pipeline([('scalar', StandardScaler()),
        ('clf', clf)
    ])
    classifier.fit(x_train, y_train)
    return classifier
```

**Evaluate the performance of a classifier**

```{python}
def holdout_score(y_test, y_pred):
    return_str = ''
    accuracy = metrics.accuracy_score(y_test, y_pred)
    return_str += 'Accuracy: {}'.format( accuracy ) + '\n'
    return_str += 'Error: {}'.format( 1 - accuracy ) + '\n'
    return_str += 'Precision: {}'.format( metrics.precision_score(y_test, y_pred, average = None) ) + '\n'
    return_str += 'Recall: {}'.format( metrics.recall_score(y_test, y_pred, average = None) ) + '\n'
    return_str += 'F1 Score: {}'.format( metrics.f1_score(y_test, y_pred, average = None) )
    return return_str
```

## Decision Tree Classifier

```{python}
def decision_tree(x_train, y_train):
    classifier = train_classifier(DecisionTreeClassifier(criterion = "entropy", class_weight={1: 2}), x_train, y_train)
    y_pred = classifier.predict(x_test)
    conf_matrix = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot = True, fmt = ".3f", square = True, cmap = plt.cm.Blues)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion matrix')
    plt.tight_layout()
    print(holdout_score(y_test, y_pred))
```

```{python}
decision_tree(x_train, y_train)
```

## K-Nearest Neighbours Classifier

```{python}
def k_nearest_neighbors(x_train, y_train):
    classifier = train_classifier(KNeighborsClassifier(n_neighbors = 3), x_train, y_train)
    y_pred = classifier.predict(x_test)
    conf_matrix = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot = True, fmt = ".3f", square = True, cmap = plt.cm.Blues)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion matrix')
    plt.tight_layout()
    print(holdout_score(y_test, y_pred))
```

```{python}
k_nearest_neighbors(x_train, y_train)
```

## Naive Bayes Classifier

```{python}
def naive_bayes(x_train, y_train):
    classifier = train_classifier(GaussianNB(), x_train, y_train)
    y_pred = classifier.predict(x_test)
    conf_matrix = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot = True, fmt = ".3f", square = True, cmap = plt.cm.Blues)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion matrix')
    plt.tight_layout()
    print(holdout_score(y_test, y_pred))
```

```{python}
naive_bayes(x_train, y_train)
```

## SVM Classifier

```{python}
def svm(x_train, y_train):
    classifier = train_classifier(SVC(kernel='rbf', class_weight={1: 2.16}), x_train, y_train)
    y_pred = classifier.predict(x_test)
    conf_matrix = metrics.confusion_matrix(y_test, y_pred)
    sns.heatmap(conf_matrix, annot = True, fmt = ".3f", square = True, cmap = plt.cm.Blues)
    plt.ylabel('Actual')
    plt.xlabel('Predicted')
    plt.title('Confusion matrix')
    plt.tight_layout()
    print(holdout_score(y_test, y_pred))
```

```{python}
svm(x_train, y_train)
```

```{python}

```
